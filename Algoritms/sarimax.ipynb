{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aleja\\anaconda3\\envs\\weather_forecast\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "\n",
    "from datetime import datetime\n",
    "from pmdarima import auto_arima\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, root_mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Data/transformed/transformed_open_meteo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>temperature_2m_max</th>\n",
       "      <th>temperature_2m_min</th>\n",
       "      <th>temperature_2m_mean</th>\n",
       "      <th>precipitation_sum</th>\n",
       "      <th>windspeed_10m_max</th>\n",
       "      <th>provincia</th>\n",
       "      <th>sin_day_of_year</th>\n",
       "      <th>cos_day_of_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>12.3</td>\n",
       "      <td>9.3</td>\n",
       "      <td>10.8</td>\n",
       "      <td>1.2</td>\n",
       "      <td>19.8</td>\n",
       "      <td>A Coruña</td>\n",
       "      <td>0.017166</td>\n",
       "      <td>0.999853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>12.4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.4</td>\n",
       "      <td>A Coruña</td>\n",
       "      <td>0.034328</td>\n",
       "      <td>0.999411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-03</td>\n",
       "      <td>16.1</td>\n",
       "      <td>6.4</td>\n",
       "      <td>10.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.1</td>\n",
       "      <td>A Coruña</td>\n",
       "      <td>0.051479</td>\n",
       "      <td>0.998674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>15.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.3</td>\n",
       "      <td>A Coruña</td>\n",
       "      <td>0.068615</td>\n",
       "      <td>0.997643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-05</td>\n",
       "      <td>14.2</td>\n",
       "      <td>4.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>A Coruña</td>\n",
       "      <td>0.085731</td>\n",
       "      <td>0.996318</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  temperature_2m_max  temperature_2m_min  temperature_2m_mean  \\\n",
       "0  2013-01-01                12.3                 9.3                 10.8   \n",
       "1  2013-01-02                12.4                 6.0                  9.1   \n",
       "2  2013-01-03                16.1                 6.4                 10.1   \n",
       "3  2013-01-04                15.2                 5.0                  9.0   \n",
       "4  2013-01-05                14.2                 4.1                  8.2   \n",
       "\n",
       "   precipitation_sum  windspeed_10m_max provincia  sin_day_of_year  \\\n",
       "0                1.2               19.8  A Coruña         0.017166   \n",
       "1                0.0               20.4  A Coruña         0.034328   \n",
       "2                0.0               17.1  A Coruña         0.051479   \n",
       "3                0.0               11.3  A Coruña         0.068615   \n",
       "4                0.0                9.7  A Coruña         0.085731   \n",
       "\n",
       "   cos_day_of_year  \n",
       "0         0.999853  \n",
       "1         0.999411  \n",
       "2         0.998674  \n",
       "3         0.997643  \n",
       "4         0.996318  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_variables = ['temperature_2m_max','temperature_2m_min','temperature_2m_mean', 'precipitation_sum', 'windspeed_10m_max']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df = df.sort_values('date')\n",
    "df.set_index('date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'day_of_year' not in df.columns:\n",
    "    df['day_of_year'] = df.index.dayofyear\n",
    "df['sin_day_of_year'] = np.sin(2 * np.pi * df['day_of_year'] / 365)\n",
    "df['cos_day_of_year'] = np.cos(2 * np.pi * df['day_of_year'] / 365)\n",
    "X = df[['sin_day_of_year', 'cos_day_of_year']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeros 3 registros de la serie:\n",
      "            temperature_2m_max  temperature_2m_min  temperature_2m_mean  \\\n",
      "date                                                                      \n",
      "2013-01-01                12.3                 9.3                 10.8   \n",
      "2013-01-01                10.0                 4.9                  7.2   \n",
      "2013-01-01                18.9                14.9                 16.7   \n",
      "\n",
      "            precipitation_sum  windspeed_10m_max   provincia  sin_day_of_year  \\\n",
      "date                                                                            \n",
      "2013-01-01                1.2               19.8    A Coruña         0.017213   \n",
      "2013-01-01                4.9               20.7    La Rioja         0.017213   \n",
      "2013-01-01                0.0               22.6  Las Palmas         0.017213   \n",
      "\n",
      "            cos_day_of_year  day_of_year  \n",
      "date                                      \n",
      "2013-01-01         0.999852            1  \n",
      "2013-01-01         0.999852            1  \n",
      "2013-01-01         0.999852            1  \n"
     ]
    }
   ],
   "source": [
    "print(\"Primeros 3 registros de la serie:\")\n",
    "print(df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observaciones en entrenamiento: 184636\n",
      "Observaciones en test: 46160\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_dummy_train, y_dummy_test = train_test_split(X, df[pred_variables[0]], test_size=0.2, shuffle=False)\n",
    "print(f\"Observaciones en entrenamiento: {len(X_train)}\")\n",
    "print(f\"Observaciones en test: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Procesando la variable: temperature_2m_max ===\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [184636, 9601072]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      9\u001b[39m y_test  = y.loc[X_test.index]\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Adicionalmente, dividir el conjunto de entrenamiento en subentrenamiento y validación para la optimización\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m X_train_sub, X_val, y_train_sub, y_val = \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSubentrenamiento: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(y_train_sub)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Validación: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(y_val)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# 4.1. Definir la función objetivo para Optuna (para la variable actual)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aleja\\anaconda3\\envs\\weather_forecast\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    212\u001b[39m         skip_parameter_validation=(\n\u001b[32m    213\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    214\u001b[39m         )\n\u001b[32m    215\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    218\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    219\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    222\u001b[39m     msg = re.sub(\n\u001b[32m    223\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    224\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    225\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    226\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aleja\\anaconda3\\envs\\weather_forecast\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2848\u001b[39m, in \u001b[36mtrain_test_split\u001b[39m\u001b[34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[39m\n\u001b[32m   2845\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n_arrays == \u001b[32m0\u001b[39m:\n\u001b[32m   2846\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mAt least one array required as input\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m2848\u001b[39m arrays = \u001b[43mindexable\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2850\u001b[39m n_samples = _num_samples(arrays[\u001b[32m0\u001b[39m])\n\u001b[32m   2851\u001b[39m n_train, n_test = _validate_shuffle_split(\n\u001b[32m   2852\u001b[39m     n_samples, test_size, train_size, default_test_size=\u001b[32m0.25\u001b[39m\n\u001b[32m   2853\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aleja\\anaconda3\\envs\\weather_forecast\\Lib\\site-packages\\sklearn\\utils\\validation.py:532\u001b[39m, in \u001b[36mindexable\u001b[39m\u001b[34m(*iterables)\u001b[39m\n\u001b[32m    502\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[32m    503\u001b[39m \n\u001b[32m    504\u001b[39m \u001b[33;03mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    528\u001b[39m \u001b[33;03m[[1, 2, 3], array([2, 3, 4]), None, <...Sparse...dtype 'int64'...shape (3, 1)>]\u001b[39;00m\n\u001b[32m    529\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    531\u001b[39m result = [_make_indexable(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m iterables]\n\u001b[32m--> \u001b[39m\u001b[32m532\u001b[39m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aleja\\anaconda3\\envs\\weather_forecast\\Lib\\site-packages\\sklearn\\utils\\validation.py:475\u001b[39m, in \u001b[36mcheck_consistent_length\u001b[39m\u001b[34m(*arrays)\u001b[39m\n\u001b[32m    473\u001b[39m uniques = np.unique(lengths)\n\u001b[32m    474\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) > \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m475\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    476\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    477\u001b[39m         % [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[32m    478\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: Found input variables with inconsistent numbers of samples: [184636, 9601072]"
     ]
    }
   ],
   "source": [
    "for var in pred_variables:\n",
    "    print(f\"\\n=== Procesando la variable: {var} ===\")\n",
    "    \n",
    "    # Extraer la serie objetivo\n",
    "    y = df[var]\n",
    "    \n",
    "    # Dividir la serie en entrenamiento y test utilizando la misma partición definida anteriormente\n",
    "    y_train = y.loc[X_train.index]\n",
    "    y_test  = y.loc[X_test.index]\n",
    "    \n",
    "    # Adicionalmente, dividir el conjunto de entrenamiento en subentrenamiento y validación para la optimización\n",
    "    X_train_sub, X_val, y_train_sub, y_val = train_test_split(X_train, y_train, test_size=0.2, shuffle=False)\n",
    "    print(f\"Subentrenamiento: {len(y_train_sub)}, Validación: {len(y_val)}\")\n",
    "    \n",
    "    # 4.1. Definir la función objetivo para Optuna (para la variable actual)\n",
    "    def objective(trial):\n",
    "        # Espacio de búsqueda para los hiperparámetros de SARIMAX\n",
    "        p = trial.suggest_int(\"p\", 0, 3)\n",
    "        d = trial.suggest_int(\"d\", 0, 2)\n",
    "        q = trial.suggest_int(\"q\", 0, 3)\n",
    "        # Parámetros para el componente estacional\n",
    "        P = trial.suggest_int(\"P\", 0, 1)\n",
    "        D = trial.suggest_int(\"D\", 0, 1)\n",
    "        Q = trial.suggest_int(\"Q\", 0, 1)\n",
    "        m = 1  # Como usamos variables exógenas para capturar la estacionalidad, m se fija en 1\n",
    "\n",
    "        try:\n",
    "            # Entrenar modelo SARIMAX en el subentrenamiento\n",
    "            model = SARIMAX(y_train_sub, exog=X_train_sub, order=(p, d, q), seasonal_order=(P, D, Q, m))\n",
    "            model_fit = model.fit(disp=False)\n",
    "            # Predecir en el conjunto de validación\n",
    "            y_pred_val = model_fit.predict(start=y_val.index[0], end=y_val.index[-1], exog=X_val)\n",
    "            rmse = mean_squared_error(y_val, y_pred_val, squared=False)\n",
    "        except Exception as e:\n",
    "            rmse = float('inf')\n",
    "        return rmse\n",
    "\n",
    "    # 4.2. Optimización de hiperparámetros con Optuna\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(objective, n_trials=50)\n",
    "    \n",
    "    best_params = study.best_params\n",
    "    print(\"Mejores hiperparámetros encontrados:\")\n",
    "    print(best_params)\n",
    "    print(f\"Mejor RMSE en validación: {study.best_value:.2f}\")\n",
    "    \n",
    "    # 4.3. Entrenar el modelo final con los mejores hiperparámetros en todo el conjunto de entrenamiento\n",
    "    p, d, q = best_params[\"p\"], best_params[\"d\"], best_params[\"q\"]\n",
    "    P, D, Q = best_params[\"P\"], best_params[\"D\"], best_params[\"Q\"]\n",
    "    m = 1\n",
    "    \n",
    "    final_model = SARIMAX(y_train, exog=X_train, order=(p, d, q), seasonal_order=(P, D, Q, m))\n",
    "    final_model_fit = final_model.fit(disp=False)\n",
    "    \n",
    "    # 4.4. Predecir en el conjunto de test\n",
    "    y_test_pred = final_model_fit.predict(start=y_test.index[0], end=y_test.index[-1], exog=X_test)\n",
    "    \n",
    "    # 4.5. Evaluar el modelo final en test usando métricas de sklearn\n",
    "    mae = mean_absolute_error(y_test, y_test_pred)\n",
    "    rmse = mean_squared_error(y_test, y_test_pred, squared=False)\n",
    "    print(f\"Evaluación en test para {var}: MAE = {mae:.2f}, RMSE = {rmse:.2f}\")\n",
    "    \n",
    "    # Almacenar resultados\n",
    "    results[var] = {\n",
    "        'model': final_model_fit,\n",
    "        'best_params': best_params,\n",
    "        'y_test': y_test,\n",
    "        'y_pred': y_test_pred,\n",
    "        'mae': mae,\n",
    "        'rmse': rmse\n",
    "    }\n",
    "\n",
    "# Opcional: visualizar un resumen de resultados\n",
    "print(\"\\nResumen final de métricas:\")\n",
    "for var, res in results.items():\n",
    "    print(f\"{var} - MAE: {res['mae']:.2f}, RMSE: {res['rmse']:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "weather_forecast",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
