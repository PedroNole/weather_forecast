{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pmdarima as pm\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Cargar y preparar el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones del dataset: (230796, 8)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../Data/transformed/transformed_open_meteo.csv')\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df.set_index('date', inplace=True)\n",
    "df.sort_index(inplace=True)\n",
    "print(\"Dimensiones del dataset:\", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Definir las variables a predecir (targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_objetivo = ['temperature_2m_max', 'temperature_2m_min', 'temperature_2m_mean', 'windspeed_10m_max', 'precipitation_sum']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Obtener todas las provincias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "provincias = df['provincia'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Detección de Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Método IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectar_outliers(series, threshold=1.5):\n",
    "    q1 = series.quantile(0.25)\n",
    "    q3 = series.quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    limite_inferior = q1 - threshold * iqr\n",
    "    limite_superior = q3 + threshold * iqr\n",
    "    return (series < limite_inferior) | (series > limite_superior)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Auto Arima "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ajustar_modelo_auto_arima(serie, pasos_forecast=7, seasonal=True, m=7):\n",
    "    modelo_auto = pm.auto_arima(serie, seasonal=seasonal, m=m,\n",
    "                                trace=False, error_action='ignore', suppress_warnings=True)\n",
    "    order = modelo_auto.order\n",
    "    seasonal_order = modelo_auto.seasonal_order\n",
    "    print(f\"Mejores parámetros: order={order}, seasonal_order={seasonal_order}\")\n",
    "    \n",
    "    modelo = SARIMAX(serie, order=order, seasonal_order=seasonal_order)\n",
    "    resultado = modelo.fit(disp=False)\n",
    "    \n",
    "    pred = resultado.get_forecast(steps=pasos_forecast)\n",
    "    df_pred = pred.summary_frame()\n",
    "    \n",
    "    return df_pred, order, seasonal_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_predicciones = []\n",
    "pasos_forecast = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Procesando provincia: A Coruña\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'province'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aleja\\anaconda3\\envs\\weather_forecast\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'province'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m provincia \u001b[38;5;129;01min\u001b[39;00m provincias:\n\u001b[32m      3\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mProcesando provincia: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprovincia\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     df_prov = df[\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mprovince\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m == provincia].copy()\n\u001b[32m      6\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m variables_objetivo:\n\u001b[32m      7\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mProcesando variable: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvar\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m en provincia: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprovincia\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aleja\\anaconda3\\envs\\weather_forecast\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4102\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4104\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aleja\\anaconda3\\envs\\weather_forecast\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3810\u001b[39m     ):\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'province'"
     ]
    }
   ],
   "source": [
    "# 2. Iterar sobre cada provincia y cada variable\n",
    "for provincia in provincias:\n",
    "    print(f\"\\nProcesando provincia: {provincia}\")\n",
    "    df_prov = df[df['provincia'] == provincia].copy()\n",
    "    \n",
    "    for var in variables_objetivo:\n",
    "        print(f\"\\nProcesando variable: {var} en provincia: {provincia}\")\n",
    "        \n",
    "        # Detectar outliers e imputar: reemplazar outliers por NaN y luego interpolar\n",
    "        outliers = detectar_outliers(df_prov[var], threshold=3)\n",
    "        df_prov.loc[outliers, var] = np.nan\n",
    "        df_prov[var] = df_prov[var].interpolate(method='time')\n",
    "        df_prov[var] = df_prov[var].fillna(method='bfill').fillna(method='ffill')\n",
    "        \n",
    "        # Validar que haya suficientes datos para train-test\n",
    "        if len(df_prov) <= pasos_forecast:\n",
    "            print(f\"No hay suficientes datos para train-test en {provincia} - {var}\")\n",
    "            continue\n",
    "        \n",
    "        # 3. Dividir la serie en entrenamiento y test\n",
    "        train = df_prov[var].iloc[:-pasos_forecast]\n",
    "        test = df_prov[var].iloc[-pasos_forecast:]\n",
    "        \n",
    "        try:\n",
    "            # Ajustar el modelo usando auto_arima sobre el conjunto de entrenamiento\n",
    "            df_pred, order, seasonal_order = ajustar_modelo_auto_arima(\n",
    "                train, pasos_forecast=pasos_forecast, seasonal=True, m=7)\n",
    "            \n",
    "            # Alinear el índice de la predicción con el de la serie de test\n",
    "            df_pred.index = test.index\n",
    "            \n",
    "            # Preparar DataFrame con los resultados para guardar en CSV\n",
    "            df_pred_reset = df_pred.reset_index().rename(columns={'index': 'forecast_date'})\n",
    "            df_pred_reset['provincia'] = provincia\n",
    "            df_pred_reset['variable'] = var\n",
    "            df_pred_reset['actual'] = test.values\n",
    "            lista_predicciones.append(df_pred_reset)\n",
    "            \n",
    "            # 4. Visualizar el resultado con Plotly (Train, Test y Forecast)\n",
    "            fig = go.Figure()\n",
    "            # Serie de entrenamiento\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=train.index, y=train,\n",
    "                mode='lines',\n",
    "                name='Entrenamiento'\n",
    "            ))\n",
    "            # Serie de test\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=test.index, y=test,\n",
    "                mode='lines',\n",
    "                name='Test'\n",
    "            ))\n",
    "            # Predicción (forecast)\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=df_pred.index, y=df_pred['mean'],\n",
    "                mode='lines',\n",
    "                name='Predicción'\n",
    "            ))\n",
    "            # Intervalo de confianza\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=np.concatenate([df_pred.index, df_pred.index[::-1]]),\n",
    "                y=np.concatenate([df_pred['mean_ci_upper'], df_pred['mean_ci_lower'][::-1]]),\n",
    "                fill='toself',\n",
    "                fillcolor='rgba(128,128,128,0.2)',\n",
    "                line=dict(color='rgba(255,255,255,0)'),\n",
    "                hoverinfo='skip',\n",
    "                name='Intervalo de confianza'\n",
    "            ))\n",
    "            fig.update_layout(\n",
    "                title=f\"Forecast para '{var}' en {provincia}\",\n",
    "                xaxis_title=\"Fecha\",\n",
    "                yaxis_title=var\n",
    "            )\n",
    "            fig.show()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error al procesar la variable {var} en {provincia}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Guardar todas las predicciones en un único CSV\n",
    "if lista_predicciones:\n",
    "    df_todas_pred = pd.concat(lista_predicciones, ignore_index=True)\n",
    "    columnas_ordenadas = ['province', 'variable', 'forecast_date', 'mean', 'mean_se', 'mean_ci_lower', 'mean_ci_upper', 'actual']\n",
    "    df_todas_pred = df_todas_pred[columnas_ordenadas]\n",
    "    \n",
    "    df_todas_pred.to_csv('predicciones_train_test.csv', index=False)\n",
    "    print(\"\\nArchivo CSV 'predicciones_train_test.csv' guardado correctamente.\")\n",
    "else:\n",
    "    print(\"No se generaron predicciones.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "weather_forecast",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
